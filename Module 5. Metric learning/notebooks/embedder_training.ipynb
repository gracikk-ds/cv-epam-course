{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b445d70-c5ba-49b8-9f2a-fa9f57f7c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import timm\n",
    "import umap\n",
    "import click\n",
    "import random\n",
    "import logging\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2738d167-15d0-4836-964c-6f8b089c2cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchmetrics import Accuracy, ConfusionMatrix\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from pytorch_metric_learning import losses, miners\n",
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b313ec95-e491-4d14-b0cb-7bb4a57e3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations.augmentations import CoarseDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa3629d-3523-4e86-bc0a-84181e67561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SIZE = 224\n",
    "BACKBONE = \"resnext101_32x8d\"\n",
    "\n",
    "dataset_folder = \"../data/interim/dataset_part/\"\n",
    "tb_log_dir = \"../logs\"\n",
    "model_dir = \"../models\"\n",
    "max_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073523e6-7e71-41ba-a36a-97a196dcf6f0",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f58d38-5cf0-4da9-b8c0-886a6b52ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transforms:\n",
    "    def __init__(self, segment=\"train\"):\n",
    "        if segment == \"train\":\n",
    "            transforms = [\n",
    "                albu.LongestMaxSize(max_size=224 + 5, always_apply=True, p=1),\n",
    "                albu.RandomBrightnessContrast(p=0.3),\n",
    "                albu.ColorJitter(hue=0.01, saturation=0.02, p=0.3),\n",
    "                # geometric transformations\n",
    "                albu.GridDistortion(distort_limit=0.6, p=0.3),\n",
    "                albu.ShiftScaleRotate(border_mode=1, rotate_limit=3, p=0.3),\n",
    "                albu.PadIfNeeded(\n",
    "                    min_height=224 + 5,\n",
    "                    min_width=224 + 5,\n",
    "                    always_apply=True,\n",
    "                    border_mode=0,\n",
    "                    value=(255, 255, 255),\n",
    "                ),\n",
    "                albu.RandomCrop(width=224, height=224),\n",
    "                albu.HorizontalFlip(p=0.5),\n",
    "            ]\n",
    "        else:\n",
    "            transforms = [\n",
    "                albu.LongestMaxSize(max_size=224, always_apply=True, p=1),\n",
    "                albu.PadIfNeeded(\n",
    "                    min_height=224,\n",
    "                    min_width=224,\n",
    "                    always_apply=True,\n",
    "                    border_mode=0,\n",
    "                    value=(255, 255, 255),\n",
    "                ),\n",
    "            ]\n",
    "        transforms.extend(\n",
    "            [\n",
    "                albu.Normalize(),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.transforms = albu.Compose(transforms)\n",
    "\n",
    "    def __call__(self, img, *args, **kwargs):\n",
    "        return self.transforms(image=np.array(img))[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1c05fa-0ce0-4971-a829-4b1bca3d7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        embedding_size: int = 512,\n",
    "        backbone: str = \"resnext101_32x8d\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.trunk = timm.create_model(backbone, pretrained=True)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.trunk.fc = nn.Linear(\n",
    "            in_features=self.trunk.fc.in_features,\n",
    "            out_features=embedding_size,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            nn.Linear(embedding_size, num_classes, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, inpt):\n",
    "        # get embeddings\n",
    "        emb = self.trunk(inpt)\n",
    "\n",
    "        # get logits\n",
    "        logits = self.classifier(emb)\n",
    "\n",
    "        return logits, emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4f269c8-bb6d-48b8-92af-1c25a5297d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(trainer, loader):\n",
    "    embeddings = trainer.predict(dataloaders=loader, ckpt_path=\"best\")\n",
    "\n",
    "    embs = []\n",
    "    targets = []\n",
    "    for element in embeddings:\n",
    "        emb, target = element\n",
    "        embs.append(emb)\n",
    "        targets.append(target)\n",
    "\n",
    "    embeddings, targets = torch.concat(embs), torch.concat(targets)\n",
    "    return embeddings.cpu(), targets.cpu()\n",
    "\n",
    "\n",
    "def sampling(embeddings, targets, N):\n",
    "    \"\"\"\n",
    "    stratified sampling to speed up validation\n",
    "    :param embeddings: full embeddings\n",
    "    :param targets: full targets\n",
    "    :param N: number of samples to save per class\n",
    "    :return: subsample of embeddings and targets\n",
    "    \"\"\"\n",
    "    embeddings = embeddings.numpy()\n",
    "    targets = targets.numpy()\n",
    "    df = pd.DataFrame.from_records(data=embeddings)\n",
    "    df[\"target\"] = targets\n",
    "    df = df.groupby(\"target\", group_keys=False).apply(\n",
    "        lambda x: x.sample(min(len(x), N), random_state=42)\n",
    "    )\n",
    "    targets = df[\"target\"].values\n",
    "    df.drop(columns=[\"target\"], inplace=True)\n",
    "    embeddings = df.values\n",
    "\n",
    "    return torch.tensor(embeddings).contiguous(), torch.tensor(targets).contiguous()\n",
    "\n",
    "\n",
    "def calculate_accuracy(trainer, train_dl, val_dl):\n",
    "    embeddings_train, targets_train = get_embeddings(trainer, train_dl)\n",
    "    embeddings_val, targets_val = get_embeddings(trainer, val_dl)\n",
    "    \n",
    "    embeddings_train, targets_train = sampling(embeddings_train, targets_train, 300)\n",
    "    embeddings_val, targets_val = sampling(embeddings_val, targets_val, 300)\n",
    "\n",
    "    accuracy_calculator = AccuracyCalculator(device=torch.device(\"cpu\"))\n",
    "\n",
    "    accuracies = accuracy_calculator.get_accuracy(\n",
    "        embeddings_train, embeddings_val, targets_train, targets_val, False\n",
    "    )\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "\n",
    "class Runner(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        classes,\n",
    "        mapper,\n",
    "        lr: float = 1e-3,\n",
    "        scheduler_T=1000,\n",
    "        metric_coeff: float = 0.3,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.classes = classes\n",
    "        self.lr = lr\n",
    "        self.scheduler_T = scheduler_T\n",
    "        self.criterion = CrossEntropyLoss()\n",
    "        self.metric_coeff = metric_coeff\n",
    "        self.miner = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "        self.metric_loss = losses.SubCenterArcFaceLoss(  # ArcFaceLoss\n",
    "            num_classes=len(classes), embedding_size=model.embedding_size\n",
    "        ).to(torch.device(\"cuda\"))\n",
    "\n",
    "        num_classes = len(self.classes)\n",
    "        self.mapper = mapper\n",
    "\n",
    "        self.metrics = torch.nn.ModuleDict(\n",
    "            {\n",
    "                \"accuracy\": Accuracy(\n",
    "                    num_classes=num_classes, compute_on_step=False, average=\"macro\"\n",
    "                ),\n",
    "                \"confusion_matrix\": ConfusionMatrix(\n",
    "                    num_classes=num_classes, normalize=\"true\", compute_on_step=False\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        self.accuracy_calculator = AccuracyCalculator(device=torch.device(\"cpu\"))\n",
    "\n",
    "        self.embeddings_train = []\n",
    "        self.embeddings_val = []\n",
    "        self.targets_train = []\n",
    "        self.targets_val = []\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, **kwargs):\n",
    "        images, targets = batch\n",
    "        logits, embeddings = self.model(images)\n",
    "        return embeddings, targets\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        images, targets = batch\n",
    "\n",
    "        logits, embeddings = self.model(images)\n",
    "\n",
    "        self.embeddings_train.append(embeddings.detach().cpu())\n",
    "        self.targets_train.append(targets.detach().cpu())\n",
    "\n",
    "        # calculating classification loss\n",
    "        clf_loss = self.criterion(logits, targets)\n",
    "\n",
    "        # calculating metric loss\n",
    "        hard_pairs = self.miner(embeddings, targets)\n",
    "        m_loss = self.metric_loss(embeddings, targets, hard_pairs)\n",
    "\n",
    "        loss = self.metric_coeff * clf_loss + (1 - self.metric_coeff) * m_loss\n",
    "\n",
    "        # calculating metrics\n",
    "        for i, metric in enumerate(self.metrics.values()):\n",
    "            metric.update(logits.softmax(axis=1), targets)\n",
    "\n",
    "        self.log(\n",
    "            \"Train/Metric Loss\",\n",
    "            m_loss.item(),\n",
    "            on_step=True,\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "        self.log(\n",
    "            \"Train/Classification Loss\",\n",
    "            clf_loss.item(),\n",
    "            on_step=True,\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "        self.log(\n",
    "            \"Train/LR\",\n",
    "            self.lr_schedulers().get_last_lr()[0],\n",
    "            on_step=True,\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        images, targets = batch\n",
    "        logits, embeddings = self.model(images)\n",
    "        self.embeddings_val.append(embeddings.detach().cpu())\n",
    "        self.targets_val.append(targets.detach().cpu())\n",
    "\n",
    "        clf_loss = self.criterion(logits, targets)\n",
    "\n",
    "        # calculating metrics\n",
    "        for i, metric in enumerate(self.metrics.values()):\n",
    "            metric.update(logits.softmax(axis=1), targets)\n",
    "\n",
    "        self.log(\n",
    "            \"Validation/Classification Loss\",\n",
    "            clf_loss.item(),\n",
    "            on_step=True,\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "        return clf_loss\n",
    "\n",
    "    def log_cm(self, confusion_matrix):\n",
    "        print(\"start drawing conf matrix\")\n",
    "        plt.figure(figsize=(50, 50))\n",
    "        sns.heatmap(\n",
    "            np.around(confusion_matrix.cpu().numpy(), 3),\n",
    "            annot=True,\n",
    "            cmap=\"YlGnBu\",\n",
    "            xticklabels=self.classes,\n",
    "            yticklabels=self.classes,\n",
    "        )\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf)\n",
    "        buf.seek(0)\n",
    "        image = np.array(Image.open(buf))[:, :, :3]\n",
    "        buf.close()\n",
    "        plt.clf()\n",
    "        self.logger.experiment.add_image(\n",
    "            \"conf_matr\", image, self.current_epoch, dataformats=\"HWC\"\n",
    "        )\n",
    "        print(\"done!\")\n",
    "\n",
    "    def log_umap(self, embeddings, targets):\n",
    "        print(\"run umap logger\")\n",
    "        sns.set(style=\"whitegrid\", font_scale=1.3)\n",
    "\n",
    "        print(\"     run StandardScaler\")\n",
    "        scaler = StandardScaler()\n",
    "        embeddings_scaled = scaler.fit_transform(embeddings)\n",
    "        print(\"     done!\")\n",
    "\n",
    "        print(\"     sampling\")\n",
    "        embeddings_scaled, targets = sampling(\n",
    "            torch.tensor(embeddings_scaled), torch.tensor(targets), 50\n",
    "        )\n",
    "        print(\"     done!\")\n",
    "\n",
    "        print(\"     starting umap transforms\")\n",
    "        umap_obj = umap.UMAP(n_neighbors=20, min_dist=0.15)\n",
    "        embedding_2d = umap_obj.fit_transform(embeddings_scaled.numpy())\n",
    "        print(\"     done!\")\n",
    "\n",
    "        plot_df = pd.DataFrame.from_records(data=embedding_2d, columns=[\"x\", \"y\"])\n",
    "        plot_df[\"target\"] = targets.numpy()\n",
    "        plot_df[\"target\"] = plot_df[\"target\"].apply(lambda x: self.mapper[x])\n",
    "\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        plt.title(\"UMAP\")\n",
    "        sns.scatterplot(x=\"x\", y=\"y\", data=plot_df, hue=\"target\", palette=\"Paired\")\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf)\n",
    "        buf.seek(0)\n",
    "        image = np.array(Image.open(buf))[:, :, :3]\n",
    "        buf.close()\n",
    "        plt.clf()\n",
    "        self.logger.experiment.add_image(\n",
    "            \"umap\", image, self.current_epoch, dataformats=\"HWC\"\n",
    "        )\n",
    "        print(\"done!\")\n",
    "\n",
    "    def validation_epoch_end(self, outputs) -> None:\n",
    "\n",
    "        if len(self.embeddings_train) != 0:\n",
    "            self.embeddings_train = torch.concat(self.embeddings_train)\n",
    "            self.targets_train = torch.concat(self.targets_train)\n",
    "            self.embeddings_val = torch.concat(self.embeddings_val)\n",
    "            self.targets_val = torch.concat(self.targets_val)\n",
    "            print(\"embedding example\", self.embeddings_train[0][:10])\n",
    "            print(\"embeddings train shape: \", self.embeddings_train.shape)\n",
    "            print(\"embeddings val shape: \", self.embeddings_val.shape)\n",
    "\n",
    "            self.embeddings_train, self.targets_train = sampling(\n",
    "                self.embeddings_train, self.targets_train, 300\n",
    "            )\n",
    "            self.embeddings_val, self.targets_val = sampling(\n",
    "                self.embeddings_val, self.targets_val, 300\n",
    "            )\n",
    "\n",
    "            # embeddings metrices\n",
    "            print(\"accuracy_calculator start\")\n",
    "            accuracies = self.accuracy_calculator.get_accuracy(\n",
    "                self.embeddings_train,\n",
    "                self.embeddings_val,\n",
    "                self.targets_train,\n",
    "                self.targets_val,\n",
    "                False,\n",
    "            )\n",
    "            print(\"done!\")\n",
    "\n",
    "            for name in accuracies:\n",
    "                self.log(\n",
    "                    f\"Validation/{name}\", accuracies[name], on_step=False, on_epoch=True\n",
    "                )\n",
    "\n",
    "            self.log_umap(\n",
    "                embeddings=self.embeddings_val.numpy(),\n",
    "                targets=self.targets_val.numpy(),\n",
    "            )\n",
    "\n",
    "            self.embeddings_train = []\n",
    "            self.embeddings_val = []\n",
    "            self.targets_train = []\n",
    "            self.targets_val = []\n",
    "\n",
    "        # classification metrices\n",
    "        for name, metric in self.metrics.items():\n",
    "            metric_val = metric.compute()\n",
    "            self.log(f\"Validation/{name}\", metric_val, on_step=False, on_epoch=True)\n",
    "            metric.reset()\n",
    "            if name != \"confusion_matrix\":\n",
    "                print(f\"Validation {name} = {metric_val}\")\n",
    "            else:\n",
    "                self.log_cm(metric_val)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params = list(filter(lambda p: p.requires_grad, self.model.parameters()))\n",
    "        optimizer = torch.optim.Adam(params, lr=self.lr)\n",
    "\n",
    "        if len([p for p in self.metric_loss.parameters()]) > 0:\n",
    "            optimizer.add_param_group({\"params\": self.metric_loss.parameters()})\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer=optimizer, T_max=self.scheduler_T, eta_min=1e-7\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\"scheduler\": scheduler},\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d878a42e-4c00-45de-b77e-5843acd5eb48",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b889f63-e8fb-4740-93e1-ddf03fc8caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(tb_log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "tb_log_dir_to_use = Path(tb_log_dir)\n",
    "model_dir_to_use = Path(model_dir)\n",
    "dataset_folder_to_use = Path(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95f28ae5-f407-4445-a0a9-6fdc22ebe5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric learning task!\n",
      "Number of classes in train 12\n",
      "Number of classes in val 12\n",
      "Number of classes in train & val 12\n",
      "Number of classes in train - val 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Running metric learning task!\")\n",
    "\n",
    "classes_train = set(\n",
    "    [p.name for p in (dataset_folder_to_use / \"train\").glob(\"*\")]\n",
    ")\n",
    "classes_val = set(\n",
    "    [p.name for p in (dataset_folder_to_use / \"test\").glob(\"*\")]\n",
    ")\n",
    "\n",
    "print(f\"Number of classes in train {len(classes_train)}\")\n",
    "print(f\"Number of classes in val {len(classes_val)}\")\n",
    "print(f\"Number of classes in train & val {len(classes_train & classes_val)}\")\n",
    "print(f\"Number of classes in train - val {len(classes_train - classes_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1b1acce-38e6-4e06-8920-5ea6b2c52a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating datasets\n",
      "datasets were created\n"
     ]
    }
   ],
   "source": [
    "print(\"creating datasets\")\n",
    "\n",
    "train_dataset = ImageFolder(\n",
    "    root=str(dataset_folder_to_use / \"train\"),\n",
    "    transform=Transforms(),\n",
    ")\n",
    "\n",
    "val_dataset = ImageFolder(\n",
    "    root=str(dataset_folder_to_use / \"test\"),\n",
    "    transform=Transforms(segment=\"val\"),\n",
    ")\n",
    "\n",
    "mapper = {train_dataset.class_to_idx[i]:i for i in train_dataset.class_to_idx}\n",
    "print(\"datasets were created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d2e4b93-e6fa-41eb-93e8-661bb036d5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating data loaders\n",
      "data loaders were created\n"
     ]
    }
   ],
   "source": [
    "print(\"creating data loaders\")\n",
    "sampler = MPerClassSampler(\n",
    "    train_dataset.targets,\n",
    "    m=3,\n",
    "    length_before_new_iter=len(train_dataset),\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_dataset,\n",
    "    BATCH_SIZE,\n",
    "    pin_memory=False,\n",
    "    sampler=sampler,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    val_dataset,\n",
    "    BATCH_SIZE,\n",
    "    pin_memory=False,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    ")\n",
    "print(\"data loaders were created\")\n",
    "\n",
    "assert val_dataset.classes == train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742be91-a6df-4644-a020-76bc966f785c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "577d6fd8-d195-4aa9-bcac-6fe2984c2f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating runner\n",
      "runner was created\n"
     ]
    }
   ],
   "source": [
    "print(\"creating runner\")\n",
    "runner = Runner(\n",
    "    model=EmbeddingsModel(\n",
    "        num_classes=len(classes_train),\n",
    "        backbone=BACKBONE\n",
    "    ),\n",
    "    classes=train_dataset.classes,\n",
    "    lr=1e-3,\n",
    "    scheduler_T=max_epochs,  # * len(train_dl)\n",
    "    mapper=mapper\n",
    ")\n",
    "print(\"runner was created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a92a86f-15e3-4503-87c9-175e7d788c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating trainer!\n",
      "trainer was created!\n"
     ]
    }
   ],
   "source": [
    "print(\"creating trainer!\")\n",
    "trainer = pl.Trainer(\n",
    "    log_every_n_steps=30,\n",
    "    max_epochs=max_epochs,\n",
    "    gpus=-1,\n",
    "    logger=pl.loggers.tensorboard.TensorBoardLogger(tb_log_dir_to_use),\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            dirpath=model_dir,\n",
    "            save_top_k=1,\n",
    "            verbose=True,\n",
    "            filename=\"checkpoint-{epoch:02d}\",\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            patience=10, monitor=\"Validation/accuracy\", mode=\"max\"\n",
    "        ),\n",
    "\n",
    "    ],\n",
    ")\n",
    "print(\"trainer was created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a12c4ca9-3667-480c-9729-2a7631accbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find learning rate\n",
    "# print(\"Run learning rate finder\")\n",
    "# lr_finder = trainer.tuner.lr_find(runner, train_dl)\n",
    "\n",
    "# # Pick point based on plot, or get suggestion\n",
    "# new_lr = lr_finder.suggestion()\n",
    "\n",
    "# # update hparams of the model\n",
    "# runner.hparams.lr = new_lr\n",
    "# print(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15c1043f-c6ec-4f1c-b1ce-6c04b4330346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/jupyter/train_embedder/models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type                 | Params\n",
      "-----------------------------------------------------\n",
      "0 | model       | EmbeddingsModel      | 87.8 M\n",
      "1 | criterion   | CrossEntropyLoss     | 0     \n",
      "2 | miner       | MultiSimilarityMiner | 0     \n",
      "3 | metric_loss | SubCenterArcFaceLoss | 18.4 K\n",
      "4 | metrics     | ModuleDict           | 0     \n",
      "-----------------------------------------------------\n",
      "87.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.8 M    Total params\n",
      "351.262   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run training pipeline\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.0\n",
      "start drawing conf matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: 120 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af59200bcae4a6b8c55d0f9c7aca07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding example tensor([ 0.7216,  0.0720, -0.1035, -0.4444,  0.3573, -0.1040,  0.0738,  0.0273,\n",
      "        -0.0152, -0.2014])\n",
      "embeddings train shape:  torch.Size([1056, 512])\n",
      "embeddings val shape:  torch.Size([820, 512])\n",
      "accuracy_calculator start\n",
      "done!\n",
      "run umap logger\n",
      "     run StandardScaler\n",
      "     done!\n",
      "     sampling\n",
      "     done!\n",
      "     starting umap transforms\n",
      "     done!\n",
      "done!\n",
      "Validation accuracy = 0.16911396384239197\n",
      "start drawing conf matrix\n",
      "done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding example tensor([-2.2894,  1.1505, -2.6921, -0.3550,  2.4992,  0.1322, -2.0354,  1.4891,\n",
      "        -2.6784, -2.5955])\n",
      "embeddings train shape:  torch.Size([1056, 512])\n",
      "embeddings val shape:  torch.Size([756, 512])\n",
      "accuracy_calculator start\n",
      "done!\n",
      "run umap logger\n",
      "     run StandardScaler\n",
      "     done!\n",
      "     sampling\n",
      "     done!\n",
      "     starting umap transforms\n",
      "     done!\n",
      "done!\n",
      "Validation accuracy = 0.24059827625751495\n",
      "start drawing conf matrix\n",
      "done!\n",
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"run training pipeline\")\n",
    "trainer.fit(runner, train_dl, val_dl)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e52d7-39df-4785-8fd7-c57b0b30a5a4",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27db8df5-f3ce-4e12-ac52-78694abe0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_clean = ImageFolder(\n",
    "    root=str(dataset_folder_to_use / \"train\"),\n",
    "    transform=Transforms(segment=\"test\"),\n",
    ")\n",
    "\n",
    "train_dl_clean = DataLoader(\n",
    "    train_dataset,\n",
    "    BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8083f748-0c19-489d-86fa-196fc6a511db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/jupyter/train_embedder/models/checkpoint-epoch=01-v1.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/jupyter/train_embedder/models/checkpoint-epoch=01-v1.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ceb155a1fd54532a0e11f56d2f404d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 3it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/jupyter/train_embedder/models/checkpoint-epoch=01-v1.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/jupyter/train_embedder/models/checkpoint-epoch=01-v1.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae1dc81ac184868a0458a13e8ed765c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 3it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(\n",
    "    trainer=trainer, \n",
    "    train_dl=train_dl_clean, \n",
    "    val_dl=val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c64cc06b-b849-4f5c-a60f-4857864e7acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMI': 0.20188743279380417,\n",
       " 'NMI': 0.22100368269758192,\n",
       " 'mean_average_precision': 0.13631831870650496,\n",
       " 'mean_average_precision_at_r': 0.0419861583991085,\n",
       " 'mean_reciprocal_rank': 0.3461434841156006,\n",
       " 'precision_at_1': 0.18928901200369344,\n",
       " 'r_precision': 0.1350349363728034}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2e272-4f1c-4605-b4b9-68b067bb48cd",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1627491-dbfa-4133-8243-1e768488c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "runner.model.eval()\n",
    "b = next(iter(val_dl))\n",
    "traced_model = torch.jit.trace(runner.model, b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d8c64-ee54-4538-abf9-e6175583720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {\n",
    "    \"inference_params\": {\n",
    "        \"image_height\": SIZE,\n",
    "        \"image_width\": SIZE,\n",
    "    },\n",
    "}\n",
    "traced_model.save(\n",
    "    str(model_dir_to_use / \"torchscript.pt\"),\n",
    "    _extra_files={f\"{k}.txt\": str(v) for k, v in meta.items()},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
