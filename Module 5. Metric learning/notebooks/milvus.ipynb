{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c930b9-a9a4-4917-a4fa-36e564110471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from pymilvus import (\n",
    "    connections, \n",
    "    FieldSchema, \n",
    "    CollectionSchema, \n",
    "    DataType, \n",
    "    Collection, \n",
    "    drop_collection, \n",
    "    utility\n",
    ")\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5717e9-a129-4dee-9773-f43059f48270",
   "metadata": {},
   "source": [
    "# Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd473fc-7f3c-408d-a065-7748193a7a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transforms:\n",
    "    def __init__(self):\n",
    "        transforms = [\n",
    "            albu.LongestMaxSize(max_size=224, always_apply=True, p=1),\n",
    "            albu.PadIfNeeded(\n",
    "                min_height=224,\n",
    "                min_width=224,\n",
    "                always_apply=True,\n",
    "                border_mode=0,\n",
    "                value=(255, 255, 255),\n",
    "            ),\n",
    "            albu.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "\n",
    "        self.transforms = albu.Compose(transforms)\n",
    "\n",
    "    def __call__(self, img, *args, **kwargs):\n",
    "        return self.transforms(image=np.array(img))[\"image\"]\n",
    "\n",
    "dataset_folder_to_use = Path(\"../data/interim/dataset_part/\")\n",
    "\n",
    "val_dataset = ImageFolder(\n",
    "    root=str(dataset_folder_to_use / \"train\"),\n",
    "    transform=Transforms(),\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    val_dataset,\n",
    "    32,\n",
    "    pin_memory=False,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121bca61-dff4-400c-aca9-49b1e951381c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0a4b07-3014-415d-a6b2-f37ec767412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))\n",
    "\n",
    "model = torch.jit.load(\"torchscript.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a35313-0229-4d98-8b1b-95a52fdc2d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, dataloader):\n",
    "    classes = []\n",
    "    embeddings = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(tqdm(dataloader)):\n",
    "            classes.extend(y.numpy())\n",
    "            _, embeddings_tmp = model(x.cuda())\n",
    "            embeddings_tmp = list(embeddings_tmp.cpu())\n",
    "            embeddings.extend(embeddings_tmp)\n",
    "    classes = np.array(classes)\n",
    "    embeddings = np.array([x.numpy() for x in embeddings])\n",
    "    print(f\"len embeddings: {len(embeddings)}, len classes {len(classes)}\")\n",
    "    return embeddings, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92289f76-3e58-4ab1-81f6-b1ce3d861ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0931378015740e3a63e549ec3450f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len embeddings: 1083, len classes 1083\n",
      "CPU times: user 10 s, sys: 3.71 s, total: 13.7 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings, classes = get_embeddings(model, dataloader=val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d729178-baf4-4cd7-bdad-bafa1db5a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer().fit(embeddings)\n",
    "embeddings_norm = normalizer.transform(embeddings)\n",
    "with open('pickles/normalizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(normalizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98efbc43-a8e0-40dd-8866-0f495b99ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pathes = pd.DataFrame(val_dataset.imgs, columns=[\"paths\", \"classes_idx\"])\n",
    "\n",
    "mapper = {y:x for x,y in list(zip(val_dataset.class_to_idx, val_dataset.class_to_idx.values()))}\n",
    "\n",
    "data_pathes[\"classes_names\"] = data_pathes[\"classes_idx\"].apply(lambda x: mapper[x])\n",
    "data_pathes[\"paths\"] = data_pathes[\"paths\"].apply(lambda x: Path(x).name)\n",
    "data_pathes.to_csv(\"./data_pathes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50b766f4-8e34-446b-ac27-cdeea2db3dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87f46a8e-7fda-45f8-9efa-74481d3b0054",
   "metadata": {},
   "source": [
    "# Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13754ec5-2558-40ec-9bbd-c767f96553f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection.close()\n",
    "connection = connections.connect(host='0.0.0.0', port='19530')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829d98c-44a4-46cc-9787-9851864c4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "has = utility.has_collection(\"demo_metric\")\n",
    "print(f\"Does collection demo_metric exist in Milvus: {has}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be42a7-b047-4d7d-9f6c-1a364ae357f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_collection(collection_name='demo_metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9827e-2a17-42b3-a63e-2dbdfe1a5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'demo_metric'\n",
    "\n",
    "schema = CollectionSchema([\n",
    "            FieldSchema(\"embedding_id\", DataType.INT64, is_primary=True),\n",
    "            FieldSchema(\"label_id\", DataType.INT64),\n",
    "            FieldSchema(\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=512)\n",
    "        ])\n",
    "\n",
    "collection = Collection(name=collection_name, schema=schema, using='default', shards_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7875362c-519f-4374-9e86-61652f4a17c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[i for i in range(len(classes))], \n",
    "        classes.tolist(), \n",
    "        embeddings_norm.tolist()\n",
    "       ]\n",
    "\n",
    "with open('pickles/embeddings.pickle', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c854f-d4a2-46d7-9ccc-b5e4f0b14820",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.insert(data)\n",
    "\n",
    "index_params = {\n",
    "        \"metric_type\":\"L2\",\n",
    "        \"index_type\":\"IVF_FLAT\",\n",
    "        \"params\":{\"nlist\":1024}\n",
    "    }\n",
    "collection.create_index(\"embeddings\", index_params=index_params)\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0449b443-b1b4-4d4a-af41-2d6f414aa0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/mapper_faces.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_dataset.class_to_idx, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce978f77-abc8-4139-a964-b0e70e9cd446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
